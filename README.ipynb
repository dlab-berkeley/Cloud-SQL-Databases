{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2da83f-cc8d-4e0f-b6f3-026c4f8b2416",
   "metadata": {},
   "source": [
    "# D-Lab Cloud SQL Databases Workshop\n",
    "\n",
    "[![Datahub](https://img.shields.io/badge/launch-datahub-blue)](http://dlab.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fdlab-berkeley%2FCloud-SQL-Databases&urlpath=lab%2Ftree%2FCloud-SQL-Databases%2F) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/dlab-berkeley/Cloud-SQL-Databases/HEAD) [![License: CC BY 4.0](https://img.shields.io/badge/License-CC_BY_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)\n",
    "\n",
    "This repository contains the materials for D-Lab’s SQL Fundamentals workshop series. \n",
    "\n",
    "### Prerequisites\n",
    "Some prior experience with SQL and Python is preferable.\n",
    "\n",
    "Check D-Lab's [Learning Pathways](https://dlab-berkeley.github.io/dlab-workshops/python_path.html) to figure out which of our workshops to take!\n",
    "\n",
    "\n",
    "## Workshop Goals\n",
    "\n",
    "This is a hands-on workshop on analyzing Social Media Data using Cloud Databases, specifically Google Cloud Platform's BigQuery. In this session, you'll learn how to leverage existing Reddit and other publicly available datasets in the cloud, import additional data, and perform meaningful analyses relevant to social science research. By the end of this workshop, you will:\n",
    "\n",
    "**NOTE for LBL Employees:** Please be aware that for LBNL employees all research use of social media data and publicly available data about people must be reviewed by the The Human & Animal Regulatory Committees (HARC) Office. Email HARC@lbl.gov(link sends e-mail) for more information.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completing Cloud SQL Databases, you will be able to:\n",
    "• Understand the basics of Google Cloud Platform (GCP) and BigQuery.\n",
    "• Explore and query public datasets on BigQuery, focusing on Reddit and Wikipedia data.\n",
    "• Perform complex SQL queries to extract meaningful insights from large datasets.\n",
    "• Cross-reference Reddit and Wikipedia data with other public datasets.\n",
    "• Import external data (e.g., data available through the UC Berkeley Library) into BigQuery.\n",
    "• Use Python and PRAW to scrape recent Reddit data and import it into BigQuery.\n",
    "• Develop skills in data analysis relevant to computational social science.\n",
    "    \n",
    "This workshop does **not** cover the following:\n",
    "- Basics of SQL or Python. This is covered in [SQL Fundamentals](https://github.com/dlab-berkeley/SQL-Fundamentals/).\n",
    "\n",
    "## Workshop Structure\n",
    "\n",
    "Cloud SQL Databases is a 2 hour workshop, and is delivered in a lecture-style coding walkthrough interrupted by challenge problems and a break. Instructors and TAs are dedicated to engaging you in the classroom and answering questions in plain language.\n",
    "\n",
    "1. **[Part 1: SQLite Installation](SQLite-Setup.ipynb)**\n",
    "2. **[Part 2: Simple SQLite Queries](Simple-SQLite-Lesson.ipynb)**\n",
    "3. **[Part 3: Northwind Database Overview](SQL-Northwind-Lesson-Overview.ipynb)**\n",
    "4. **[Part 4: Northwind SQLite Exercises](SQL-Northwind-Lesson-Exercises.ipynb)**\n",
    "\n",
    "## Installation Instructions\n",
    "\n",
    "Before attending the workshop, you should install Python and Jupyter to your computer. If you need help, please submit a [consulting request](https://dlab.berkeley.edu/consulting/submit-consulting-request) with D-Lab prior to the start of the workshop.\n",
    "\n",
    "Then follow the steps in the [installation instructions notebook](SQLite-Setup.ipynb)\n",
    "\n",
    "## Is Python not working on your laptop?\n",
    "\n",
    "If you do not have Anaconda installed and the materials loaded on your workshop by the time it starts, we *strongly* recommend using the UC Berkeley Datahub to run the materials for these lessons. You can access the DataHub by clicking this button:\n",
    "\n",
    "[![Datahub](https://img.shields.io/badge/launch-datahub-blue)](http://dlab.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fdlab-berkeley%2FCloud-SQL-Databases&urlpath=lab%2Ftree%2FCloud-SQL-Databases%2F)\n",
    "\n",
    "The DataHub downloads this repository, along with any necessary packages, and allows you to run the materials in a Jupyter notebook that is stored on UC Berkeley's servers. No installation is necessary from your end - you only need an internet browser and a CalNet ID to log in. By using the DataHub, you can save your work and come back to it at any time. When you want to return to your saved work, just go straight to [DataHub](https://datahub.berkeley.edu), sign in, and you click on the `Cloud-SQL-Databases` folder.\n",
    "\n",
    "If you don't have a Berkeley CalNet ID, you can still run these lessons in Binder, which is another cloud-based option. Click this button:\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/dlab-berkeley/Cloud-SQL-Databases/HEAD)\n",
    "\n",
    "Note: Using Binder, you unfortunately cannot save your work.\n",
    "\n",
    "# About the UC Berkeley D-Lab\n",
    "\n",
    "D-Lab works with Berkeley faculty, research staff, and students to advance data-intensive social science and humanities research. Our goal at D-Lab is to provide practical training, staff support, resources, and space to enable you to use R for your own research applications. Our services cater to all skill levels and no programming, statistical, or computer science backgrounds are necessary. We offer these services in the form of workshops, one-to-one consulting, and working groups that cover a variety of research topics, digital tools, and programming languages.  \n",
    "\n",
    "Visit the [D-Lab homepage](https://dlab.berkeley.edu/) to learn more about us. You can view our [calendar](https://dlab.berkeley.edu/events/calendar) for upcoming events, learn about how to utilize our [consulting](https://dlab.berkeley.edu/consulting) and [data](https://dlab.berkeley.edu/data) services, and check out upcoming [workshops](https://dlab.berkeley.edu/events/workshops).\n",
    "\n",
    "# Other D-Lab Python Workshops\n",
    "\n",
    "Here are other Python workshops offered by the D-Lab:\n",
    "\n",
    "### Basic competency\n",
    "\n",
    "* [SQL Fundamentals](https://github.com/dlab-berkeley/Cloud-SQL-Databases/)\n",
    "* [Python Data Wrangling and Manipulation with Pandas](https://dlab.berkeley.edu/events/python-data-wrangling-and-manipulation-pandas/2024-10-10)\n",
    "\n",
    "# Contributors\n",
    "* Aaron Culich\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2f91f-183b-47c2-9b02-4ed203e5b8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
